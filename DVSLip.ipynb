{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# download statements",
        "!pip install tonic --quiet",
        "!pip install snntorch --quiet"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# imports",
        "import tonic",
        "from tonic import datasets",
        "import tonic.transforms as transforms",
        "import snntorch as snn",
        "from snntorch import spikeplot as splt",
        "from snntorch import spikegen",
        "import torch",
        "import torch.nn as nn",
        "from torch.utils.data import DataLoader",
        "import matplotlib.pyplot as plt",
        "import numpy as np",
        "import itertools"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# path",
        "save_to_path = '/content/drive/MyDrive/CMPM_118/DVS-Lip'",
        "batch_size = 128"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# define device (in tut5)",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")",
        "sensor_size = tonic.datasets.DVSLip.sensor_size"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "transform = transforms.Compose([",
        "    transforms.Denoise(filter_time=10000),",
        "    transforms.ToFrame(sensor_size=sensor_size, time_window=1000)",
        "])"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Custom Data Loader (MAIN ISSUE)",
        "from torch.utils.data import Dataset, DataLoader",
        "",
        "class DVSLipDataset(Dataset):",
        "    def __init__(self, save_to_path, train=True, transform=None, target_transform=None, transforms=None):",
        "        self.dataset = datasets.DVSLip(save_to=save_to_path, train=train, transform=transform,",
        "                                       target_transform=target_transform, transforms=transforms)",
        "",
        "    def __len__(self):",
        "        return len(self.dataset)",
        "",
        "    def __getitem__(self, idx):",
        "        sample = self.dataset[idx]",
        "        # You can perform additional processing on the sample if needed",
        "        return sample"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create the training and validation datasets",
        "train_dataset = DVSLipDataset(save_to_path, train=True, transform=transform)",
        "val_dataset = DVSLipDataset(save_to_path, train=False, transform=transform)"
      ],
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create the custom data loaders",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
